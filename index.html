<html>

 <!-- Automatic forward:  <meta HTTP-EQUIV="REFRESH" content="0; url=http://www.ee.surrey.ac.uk/CVSSP/profiles?s_id=5202"> --> 

  <head>
    <title> Te&oacute;filo Emidio de Campos, DPhil</title>
  </head>
  <body>
<table border=0 cellpadding=3 valign="top">
<tr><td><img src="Img/teo_frozen_beard_feb2017_small.JPG" width="220">
</td><td >
    <h1> Teo de Campos </h1>
<hr>
<table border=0 cellpadding=3> 
<tr>
<td><a href="#publications">Publications</a>
</td>
<td><a href="#students">Students</a>
</td>
<td><a href="#projects">Projects</a>
</td>
<td><a href="#datasets">Datasets</a>
<td><a href="#teaching">Teaching</a>
<td><a href="#demos">Demos</a>
</td>
<td><a href="cv.pdf">CV</a>
</td>
</tr>
</table>
<hr>
    <p>Since June 2021, I have been holding a leave of abscense from the <a target="_blank" href="http://unb.br">University of Brasilia</a> and I have been working at <a href="https://www.vicon.com" target="_blank">Vicon Motion Systems</a> (a member of the <a target="_blank" href="https://oxfordmetrics.com">Oxford Metrics Group</a>). For this reason, I am not planning to accept to supervise new students for the time being.</p>
    <p> I joined UnB as a "professor adjunto" in July 2016.
      I am also linked with the <a target="_blank" href="http://www.surrey.ac.uk/cvssp/">CVSSP</a>/<a target="_blank" href="http://www.surrey.ac.uk">University of Surrey</a>, as a "visiting researcher", where I had worked as a senior research fellow from 2009 to 2016.<BR>
      From March 2013 to April 2014 I'd also worked in the  <a target="_blank" href="http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/">Machine Learning group at the University of Sheffield</a>.<BR>
Previously, I have worked in the research laboratories of <a target="_blank" href="http://xrce.xerox.com/Research-Development/Document-Content-Laboratory/Computer-Vision">Xerox</a>, <a target="_blank" href="http://research.microsoft.com/en-us/um/people/manik/">Microsoft</a> and <a target="_blank" href="http://www.sle.sharp.co.uk/sharp/apps/sle-web/research/oids/">Sharp</a>. <BR>
I completed my DPhil in 2006 at the <a target="_blank" href="http://www.robots.ox.ac.uk/ActiveVision/">University of Oxford</a> and my <a href="MSc/">award winning MPhil thesis</a> at the <a target="_blank" href="http://www.vision.ime.usp.br/creativision">University of Sao Paulo</a>, in 2001.
<BR>
My research interests include a wide range of computer vision applications, natural language processing, <a href="TransferLearning">transfer learning</a>, anomaly detection, head tracking for <a target="_blank" href="http://www.s3a-spatialaudio.org">spatial audio</a> and semantic image segmentation.
</p>

<!--    <p> Please follow <a target="_blank" href="http://www.ee.surrey.ac.uk/CVSSP/profiles?s_id=5202">
	this link for a better looking webpage</a> which includes my contact information, but beware that it was generated (semi-)automatically and may not be updated. </p> 
<p>
<a href="calendar.html">See if I'm available</a>.<BR>
</p>
--> 
</td></tr>
</table>

<hr>
<a name="publications"></a>
<h2><a target="_blank" href="publications.html">Publications</a></h2>
<p>
<a target="_blank" href="http://scholar.google.co.uk/citations?hl=en&user=dMZCMp0AAAAJ&oi=sra">Google scholar</a> is probably the most up to date page for my list of publications, but it may not point to freely available PDF files or my papers. <BR>
The links below offer alternatives, which may include links to demonstrations, datasets, etc.
  <ul>
    <li><a target="_blank" href="http://scholar.google.co.uk/citations?hl=en&user=dMZCMp0AAAAJ&oi=sra">Google scholar</a></li>
    <li>Here is <a target="_blank" href="publications.html">a big, ugly and unsorted list of references in BibTeX format</a>.</li>
    <li><a  target="_blank" href="http://www.robots.ox.ac.uk/~teo/publications.html"> My thesis, old demos and publications from my page at Oxford</a> </li>
    <li><a target="_blank" href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Campos:Te=oacute=filo_Em=iacute=dio_de.html">DBLP</a></li>
    <li><a target="_blank" href="https://orcid.org/0000-0001-6172-0229">ORCID</a></li>
    <li><a target="_blank" href="https://arxiv.org/a/decampos_t_1.html">arXiv</a></li>
    <li><a target="_blank" href="http://lattes.cnpq.br/5052452346402051">Lattes</a> (Brazil)</li>
    <li><a target="_blank" href="http://www.surrey.ac.uk/cvssp/people/teo_de_campos/index.htm#publications">Surrey University library</a></li>
    <li> <a target="_blank" href="http://www.ee.surrey.ac.uk/CVSSP/Publications/ShortListGet.php?author=campos&amp;title=&amp;year=&amp;keywords=&amp;all=&amp;BibType=.&amp;SortBy=year&amp;query=Query+Database"> My papers at the old CVSSP library </a></li>
    <li><a target="_blank" href="https://www.linkedin.com/in/teofilo/">LinkedIn</a></li>
    <li><a target="_blank" href="https://www.researchgate.net/profile/Teofilo_De_Campos">ResearchGate</a></li>
      <!-- <li><a target="_blank" href="http://pascallin2.ecs.soton.ac.uk/Network/Researchers/1526/">PASCAL</a></li> -->
    <li><a target="_blank" href="https://academic.microsoft.com/author/2130548115">MS academic</a></li>   <!-- old link: https://academic.microsoft.com/#/detail/2109339826 -->
    <!--<li><a target="_blank" href="http://academic.research.microsoft.com/Author/319713.aspx">MS academic</a></li> -->
    <li><a target="_blank" href="http://www.ee.surrey.ac.uk/CVSSP/profiles?s_id=5202">My old page at Surrey</a></li>
  </ul>
</p>
<hr>
<a name="students">
<h2> Students and collaborators </h2>
Here is a list of people who work or had worked closely with me or under my (co-)supervision:
<ul>
  <li><a href="aloisio">Aloisio Dourado Neto</a>, PhD student (2018-present) on <a href="https://gitlab.com/UnBVision/edgenet360/-/blob/master/README.md" target="_blank">3D semantic scene completion</a>.</li>
  <li>Lindeberg Leite, PhD student (2020-present) on text mining.</li>
  <li><a href="patricia/"Patricia Medyna Drumond</a>, PhD student (2019-present) on text mining. </li>
  <li><a href="http://vision.ime.usp.br/~cejnog/" target="_blank">Luciano Cejnog</a>, PhD student (co-supervision since 2017) on 3D hand tracking for occupational therapy.</li>
  <li><a href="fred_guth/">Frederico Guth</a>, MSc student (2019-present) on <a href="https://arxiv.org/abs/1912.08812" target="_blank">transfer learning</a>.</li>
  <li><a href="peluz/">Pedro Henrique Luz de Araujo</a>, MSc student (2019-present) on document classification.</li>
  <li><a href="tiago/">Tiago de Carvalho Gallo Pereira</a>, MSc student (2019-present) and final year UG student (2018-2019) on person re-identification. </li>  
  <li>Raphael Soares, final year UG student (2019) on image compression.</li>
  <li>Guilherme Lopes, final year UG student (2019) on semantic scene completion.</li>
  <li><a target="_blank" href="https://gitlab.com/andrebsguedes">Andr&eacute; B. S. Guedes</a> was an undergrad student who has worked with me from September 2017 to July 2018 on these applications of Deep CNN: <a target="_blank" href="https://gitlab.com/andrebsguedes/gesture-cnn/blob/master/README.md">gesture recognition</a> (<a target="_blank" href="http://fga.unb.br/tcc/software/tcc-2016.2-engenharia-de-software/andre-bernardes-soares-guedes/v2-tcc-1-.pdf">see his TCC1 report, in Portuguese</a>), <a href="http://vision.cic.unb.br/">concept-based image retrieval</a> and on <a href="https://arxiv.org/abs/1802.04735" target="_blank">3D semantic scene completion from and RGB image and its depth map</a>.
    <li><a target="_blank" href="https://sites.google.com/site/moacirponti/">Moacir Ponti</a>, is a Professor Assistente at the Universidade de Sao Paulo who took a sabbatical at Surrey (Feb 2016 to Jan 2017), working with <a target="_blank" href="http://www.surrey.ac.uk/cvssp/people/josef_kittler/">Josef Kittler</a>, myself and other researchers at the CVSSP. We have collaborated in a project on classifier incongruence, in which his undergrad student Mateus Riva was also involved (as a visiting student at Surrey).</li>
  <li><a target="_blank" href="http://www.surrey.ac.uk/cvssp/people/sam_fowler/">Sam Fowler</a>, is a PhD student working on <a href="http://cvssp.org/projects/s3a/CompRecon/" target="_blank">indoors scene analysis</a> who started in October 2015, supervised by <a target="_blank" href="http://www.surrey.ac.uk/cvssp/people/adrian_hilton/">Adrian Hilton</a> and co-supervised by me until June 2016. After my move to Brasilia, Hansung Kim became his co-supervisor.</li>
  <li><a target="_blank" href="http://personal.ee.surrey.ac.uk/Personal/N.Farajidavar/">Nazli FarajiDavar</a> was a PhD student who worked on <a href="TransferLearning/">Transfer Learning (Unsupervised Domain Adaptation)</a>. She was supervised by me and co-supervised by <a target="_blank" href="http://www.surrey.ac.uk/cvssp/people/josef_kittler/">Josef Kittler</a> from September 2010 to February 2015.</li>
  <li><a target="_blank" href="http://buscatextual.cnpq.br/buscatextual/visualizacv.do?metodo=apresentar&id=K4484146E2">Estephan Dazzi</a> was a visiting student who worked with me from May 2014 to April 2015, his PhD at USP was supervised by <a target="_blank" href="http://www.ime.usp.br/~cesar/">Roberto M. Cesar-Jr</a>. We still collaborate in a project on keygraph matching.</li>
  <li><a target="_blank" href="http://www.linkedin.com/in/mariananoliveira">Mariana Nunes de Oliveira</a> was a Summer placement student from <a target="_blank" href="http://www.unb.br">UnB</a> who worked with me from June-September 2014.</li>
  <li><a target="_blank" href="http://www.linkedin.com/pub/dalia-coppi/56/418/682">Dalia Coppi</a> was a visiting student in 2012-2013, I was a co-supervisor in her visit, which was mainly supervised by <a target="_blank" href="http://www.surrey.ac.uk/cvssp/people/josef_kittler/">Josef Kittler</a>. Her PhD at UNIMORE was supervised by <a target="_blank" href="http://imagelab.ing.unimore.it/imagelab/~cucchiara/">Rita Cucchiara</a>.</li>
  <li><a target="_blank" href="http://br.linkedin.com/in/iacercalixto">Iacer Calixto</a>'s work in our <a href="VisionLanguage">V&L project</a> (2012) was co-supervised by me. <a target="_blank" href="http://staffwww.dcs.shef.ac.uk/people/L.Specia/">Lucia Specia</a> was his main supervisor.</li>
  <li>Marcelo Mergulhao Russi was my intern at <a href="Uana/">Uana Tech</a> in 2011. </li>
  <li><a target="_blank" href="http://i.stanford.edu/~julian/">Julian McAuley</a> was my intern at Xerox in 2009. His PhD at NICTA was supervised by <a target="_blank" href="http://www.tiberiocaetano.com/">Tiberio Caetano</a>.</li>
</ul>
<hr>
<a name="projects"></a>
<h2>Projects</h2>
<p>  Here is a list of projects, showing the period in which I have been involved (not necessarily the duration of the project as a whole):
  <ul>
    <li>I am the Principal Investigator of project <a href="KnEDLe/" target="_blank">KnEDLe - Knowledge Extraction from Documents of LEgal content</a> (2020-2022)</li>
    <li><a href="https://gitlab.com/UnBVision/" target="_blank">Follow this link to see the projects of UnBVision, my group at GitLab</a>, which include the projects below (among others):</li>
    <ul>
      <li><a href="https://gitlab.com/UnBVision/edgenet360/-/blob/master/README.md" target="_blank">Semantic Scene Completion from 360 cameras</a> (2019-present)</li>
      <li><a href="https://gitlab.com/UnBVision/edgenet" target="_blank">EdgeNet - 3D Semantic Segmentation using depth and 2D edges</a>.</li>
      <li><a href="https://gitlab.com/UnBVision/tf-sscnet" target="_blank">TF-SSCnet, Aloisio's implementation of SSCNet (which was originally written in Caffe) using TensorFlow</a>. This implementation has a much smaller memory footprint than the original code and it also separates pre-processing steps from the neural net pipeline, making training a lot faster.</li>
      <li><a href="https://gitlab.com/UnBVision/domain-adaptation-for-person-re-identification-on-new-unlabeled-data" target="_blank">Domain Adaptation for person re-identification</a> (2018-present).</li>
      <li><a href="https://gitlab.com/UnBVision/SkinNet" target="_blank">SkinNet - our deep CNN for skin detection</a></li>
    </ul>
    <li><a href="ViP/" target="_blank">Victor Project: an AI system for Brazil's supreme court</a> (2018-2019)</li>
    <li> <a target="_blank" href="http://vision.ime.usp.br/~cejnog/handanalysis/">Hand tracking for occupational therapy</a> (2014-present)
      <ul>
	<li><a target="_blank" href="http://www.bv.fapesp.br/pt/auxilios/91508/hand-tracking-for-occupational-therapy/">Link to the grant for collaboration between Surrey and USP, sponsored by FAPESP.</a> </li>
      <li>Download <a target="_blank" href="Img/teo_hand.stl">a 3D model of my hand</a> (requires an SDL viewer), built by <a target="_blank" href="http://www.krejov.com/">Phil Krejov</a>.</li>
      <li> <a target="_blank" href="https://gitlab.com/andrebsguedes/gesture-cnn/blob/master/README.md">Gesture recognition using deep CNNs</a>, by Andr&eacute; Guedes. </li>
    </ul>
    </li>
    <li><a href="http://vision.cic.unb.br/">Concept-based image retrieval using Deep Convolutional Neural Networks</a> (2016-2017)</li>
    <li> <a target="_blank" href="http://s3a-spatialaudio.org">S3A</a> (2014-2019)  <!-- http://gow.epsrc.ac.uk/NGBOViewGrant.aspx?GrantRef=EP/L000539/1 -->
      <ul>
	<li>Semantic scene completion in 3D. Related papers and code:
	  <ul>
	    <li><a href="https://gitlab.com/UnBVision/edgenet360/-/blob/master/README.md" target="_blank">EdgeNet360: Semantic Scene Completion from a Single 360 degree Image and Depth Map</a></li>
	    <li><a href="https://arxiv.org/abs/1908.02893" target="_blank">EdgeNet: Semantic Scene Completion from RGB-D images</a></li>
	    <li><a href="https://arxiv.org/abs/1802.04735" target="_blank">Semantic Scene Completion Combining Colour and Depth: preliminary experiments</a></li>	    
	  </ul>
	</li> 
	<li><a href="http://cvssp.org/projects/s3a/CompRecon/" target="_blank">Indoors scene analysis</a></li>
	<li><a target="_blank" href="http://epubs.surrey.ac.uk/812397/1/3DV-CameraReady.pdf">RGBD semantic segmentation using Deep CNNs</a> [<a target="_blank" href="https://youtu.be/aJ6Pf9tvm9E">demo</a>] and 3D scene completion from a depth image</li>
	<li><a href="http://cvssp.org/data/s3a/public/PersonTracking/index.html">Talker tracking</a></li>
      </ul>
    </li>
    <li> <a href="OccupationalTherapy">Hand tracking for occupational therapy</a> (2014-2017) </li> 
    <li> <a href="AMIDA/">Mitosis detection</a> (as part of my contribution to the <a target="_blank" href="http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/projects/synergy/">SYNERGY</a> project while I was in Sheffield, 2013-2014)</li>
    <li> <a target="_blank" href="http://gow.epsrc.ac.uk/NGBOViewGrant.aspx?GrantRef=EP/F02827X/1">Visual Media Research Platform Grant</a> (2013-2014)</li>
    <li> <a target="_blank" href="http://imagelab.ing.unimore.it/imagelab/researchactivity.asp?idAttivita=5">Novel (sub-)class detection</a> (2012-2013)</li>
    <li> <a href="http://kahlan.eps.surrey.ac.uk/acasva">ACASVA</a> (2009-2013) and <a href="TransferLearning/">Transfer Learning - source code available in this link</a> (2010-2014)</li>
    <li> <a target="_blank" href="http://www.pascal-network.org/">PASCAL2 Network of Excellence</a> (2009-2013)</li>
    <li> <a href="VisionLanguage">Vision4Translation</a>  - Vision and Language (2012)</li>
    <li> <a href="Uana">Uana Tech</a> - textual and visual plagiarism detection (2010-2014)</li>
    <li> <a target="_blank" href="http://www.pinview.eu">PinView</a> (2008-2009)</li>
    <li> <a href="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/">Character recognition in natural scenes</a> (2007)</li>
    <li> <a target="_blank" href="http://www.sharp-world.com/products/device/about/lcd/dual/index.html">Dual view displays</a> (2005-2007) </li>
    <li> <a target="_blank" href="http://www.robots.ox.ac.uk/~lav/Research/Projects/2006teo_hand/project.html">Human hand tracking using kinematic and appearance models</a> (2001-2005) </li>
    <li> <a target="_blank" href="http://www.vision.ime.usp.br/~creativision/projects/fselect.html">Feature selection for face recognition</a> (1999-2001) </li>
  </ul>
</p>
<p> Relevant activities I've been involved with:
  <ul>
      <li><a href="https://sibgrapi2020.cin.ufpe.br/tutorials/" target="_blank">Sibgrapi 2020 tutorials chair</a>. During the event, I hosted the tutorial of <a href="https://filipe-ufrpe.netlify.app" target="_blank">Cordeiro</a> and <a href="https://cs.adelaide.edu.au/~carneiro/" target="_blank">Carneiro</a>, on deep learning with noisy labels [<a href="https://youtu.be/Tu9xwEVDtzA" target="_blank">video</a> | <a href="https://github.com/filipe-research/tutorial_noisylabels" target="_blank">code, paper and datasets</a>]. </li>
      <li>I was one of the <a target="_blank" href="http://pamitc.org/wacv2017/people/">Area Chairs of WACV 2017</a>.</li>
      <li>From 2009 to 2013, I'd served as Surrey's local manager for the <a target="_blank" href="http://www.pascal-network.org">PASCAL2 Network of Excellence</a>, an European Union Network of Excellence which involved 1072 researchers.</li>
      <li>I have helped with the organisation of <a target="_blank" href="http://bmvc2012.surrey.ac.uk/">BMVC 2012</a> and I've chaire the <a target="_blank" href="http://bmvc2012.surrey.ac.uk/workshop.php">students' workshop</a>.</li>
      <li>I've served as one of the area chairs of <a target="_blank" href="http://www.visapp.visigrapp.org/">VISAPP 2012</a>.</li>
      <li>I was a member of the <a target="_blank" href="http://www.vlnet.org.uk/">V&L net</a>. As part of it, I'm co-leading a <a href="VisionLanguage">pump-priming project on the use of Vision as context for Machine Translation</a>.</li>
      <li>I have co-chaired the <a target="_blank" href="http://www.pascal-network.org/?q=node/735">Computer Vision sessions at the EURO 2012 conference</a>.</li>
      <li>I regularly review papers for CVPR, ICCV, ECCV, NIPS, BMVC, PAMI, PR and PRL, among other top vision conferences and journals.</li>
      <li>I've ridden a unicycle for the benefit of research: <a target="_blank" href="http://info.ee.surrey.ac.uk/Personal/J.Guillemaut/publications/11/Imre3DIMPVT11.pdf">Imre et al 3DIMPVT 2011</a>, <a target="_blank" href="http://info.ee.surrey.ac.uk/Personal/J.Guillemaut/publications/11/Imre3DIMPVT11/videos/">videos</a>.</li>
      <li>I've been trying to learn how to teach. <a target="_blank" href="http://youtu.be/NhoN4HeppTU">Here is what happens when I try to teach something without much preparation</a>.</li>
    </ul>
    </p>
<hr>
<a name="datasets"></a>
<h2>Datasets</h2>
<p> 
  <ul>
    <li><a href="ViP/" target="_blank">Victor dataset</a></li>
    <li><a href="LeNER-Br/" target="_blank">LeNER-Br: a Dataset for Named Entity Recognition in Brazilian Legal Text</a> </li>
    <li> <a target="_blank" href="http://cvssp.org/data/s3a/public/speaker_tracking_kinect2_register.php">Audio-visual tracking</a></li>
      <li> <a href="VisionLanguage"> Vision4Translation (VLnet)</a> - Using images as context for machine translation</li>
      <li> <a target="_blank" href="http://kahlan.eps.surrey.ac.uk/acasva/Downloads.html"> ACASVA actions</a> - tennis and badminton actions</li>
      <li> <a href="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"> Chars74K </a> - characters used in English and Kannada</li>
</ul>
</p>
<hr />
<a name="teaching"></a>
<h2>Teaching</h2>
<p>This section is to be constructed, but you can follow this link to see a <a href="AI_ML_courses.html" target="_blank">list of courses in the field of Artificial Intelligence and Machine Learning that are offered at UnB</a>.</p>
<hr />
<a name="demos"></a>
<h2>Demos and Media Appearances</h2>
<table border=0 valign="top">
  <tr>
    <td><iframe width="200" src="https://www.youtube.com/embed/gxICIj8cfc8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </td>
    <td >Intrudocing myself to Computer Vision students (in Portuguese, August 2020).
    </td>
  </tr>
  <tr>
    <td><iframe width="200" src="https://www.youtube.com/embed/DtoOHR7xIx4" frameborder="0" allowfullscreen></iframe>
    </td>
    <td >
      I've featured in a local TV channel
      (<a target="_blank" href="http://www.unbtv.unb.br/">UnB
	TV</a>), <a target="_blank" href="https://youtu.be/DtoOHR7xIx4">discussing Deep
	Learning</a> with <a target="_blank" href="http://cic.unb.br/~ghedini/">my
	colleague Celia Ghedini Ralha</a>
      (<a target="_blank" href="https://youtu.be/DtoOHR7xIx4">in Portuguese</a>, May
      2017).
    </td>
  </tr>
  <tr>
    <td>
      <a target="_blank" href="https://www.newscientist.com/article/2116970-computer-vision-algorithms-pick-out-petty-crime-in-cctv-footage/">
	<img width="200" src="Img/new_scientist.jpg"/></a>
    </td>
    <td>
      I've contributed to a <a target="_blank" href="https://www.newscientist.com/article/2116970-computer-vision-algorithms-pick-out-petty-crime-in-cctv-footage/">NewScientist article about visual sourveillance, by Tim Revell</a> (January 2017).
    </td>
  </tr>
</table>

<hr width="80%" align="center">
<h3>  </h3>
<table border=0 valign="top">
  <tr>
    <td><iframe width="200" src="https://www.youtube.com/embed/aJ6Pf9tvm9E" frameborder="0" allowfullscreen></iframe>
    </td>
    <td >
      <a target="_blank" href="https://youtu.be/aJ6Pf9tvm9E">Room Layout Estimation with Object and Material Attributes Information using a Spherical Camera, with Semantic Segmentation from RGBD Images</a> (Presented by <a target="_blank" href="http://www.3dkim.com">Hansung Kim</a>, <a target="_blank" href="http://3dv.stanford.edu"> at 3DV, October 2016</a>, <a target="_blank" href="https://doi.org/10.1109/3DV.2016.83">DOI 10.1109/3DV.2016.83</a>)
    </td>
  </tr>
</table>
<hr width="80%" align="center">
<h3> Concept-based image retrieval using a Deep Convolutional Neural Network </h3>
<ul><li>  <a href="http://vision.cic.unb.br/">Online demo</a></li>
  <li><a target="_blank" href="https://gitlab.com/andrebsguedes/das-caffe-images">Source code</a>
</ul>
<hr width="80%" align="center">
<h3>Head/Face Tracking</h3>
Here a some demos that I made to evaluate other people's head/face trackers
<table border=0 valign="top">
  <tr>
    <td><iframe width="200" src="https://www.youtube.com/embed/YzX11qxogvo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </td>
    <td > Demonstration of the head pose estimation method based on Random Forests, using Kinect, created using the method of <a href="http://files.is.tue.mpg.de/jgall/projects/RFhead/RFhead.html" target="_blank">Gabriele Fanelli and others at ETHZ</a>.
    </td>
  </tr>
  <tr>
    <td> <iframe width="200" src="https://www.youtube.com/embed/kCJR6c32o4Y" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </td>
    <td >Facial feature tracker using Active Appearance Model, code written by <a href="http://jsaragih.org" target="_blank">Jason Saragih</a> - who did a PhD with <a href="http://www.simonlucey.com" target="_blank">Simon Lucey</a>. <BR />
      Source code available from <a href="https://github.com/kylemcdonald/FaceTracker" target="_blank">GitHub</a>.
    </td>
  </tr>
  <tr>
    <td> <iframe width="200" src="https://www.youtube.com/embed/QBj4DoHnGFs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </td>
    <td>Face detector combining frontal, profile and ears detectors based on Viola and Jones' method, implemented using OpenCV.
    </td>
  </tr>  
</table>

<hr width="80%" align="center">
<h3>3D Trackers from my PhD</h3>
<table border=0 valign="top">
  <tr>
    <td>
      <img width="200" src="Img/hand_box_demo_small.gif">
    </td>
    <td>
      <ul>
	<li><a href="http://www.robots.ox.ac.uk/~teo/thesis"> 3D articulated object tracking</a> (demos from my thesis)</li>
	<li><a target="_blank" href="http://www.robots.ox.ac.uk/ActiveVision/Papers/tordoff_etal_bmvc2002/tordoff_etal_bmvc2002.html">3D head tracking to control a wearable robot</a> (work lead by Walterio Mayol and Ben Tordoff, supervised by David Murray)</li>
      </ul>
    </td>
  </tr>
</table>

<hr width="80%" align="center">
<H3><a target="_blank" href="http://kahlan.eps.surrey.ac.uk/acasva">ACASVA project</a> videos</H3>
<p>In the video below, I present a short summary of some of the main aspects of this project:</p>
<a target="_blank" href="http://videolectures.net/machine_de_campos_video_annotation/">
<img src="http://hydro.ijs.si/v00d/d0/2c2hqynnudobfwdutjb3jub4hmeqxvcn.jpg"></a>

<hr align="center" width=80%>

<p>The video below demonstrates tracking, court detection, homography computation and event detection: </p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/F7E1lQKmmW0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<hr align="center" width=80%>


<p>Here is another video, showing the annotation tool that I have developed:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2Tumkg_h6o8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<hr align="center" width=80%>
<h3>Images as sets of locally weighted features</h3>
<p>Follow <a target="_blank" href="http://research.microsoft.com/apps/video/dl.aspx?id=135891">this link for a talk I presented at Microsoft Research</a> in Cambridge, 2010.</p>
<a target="_blank" href="http://research.microsoft.com/apps/video/dl.aspx?id=135891">
    <img src="Img/catFishPatent.png" width=600> </a>
    <BR>
(Fig. 6 of <a target="_blank" href="http://www.google.com/patents/US20100189354">US 2010/0189354</a>)
<hr>
    <address><a href="mailto:xxxxxxxxxxx@unb.br">teodecampos</a></address>
    <!-- Created: Fri Aug 14 16:32:57 BST 2009 -->
    <!-- hhmts start -->
Last modified: 14 October 2021
<!-- hhmts end -->
  </body>
</html>
